{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqwmt4F3UGpI",
        "outputId": "bdb8ca83-d3a1-4026-cd96-1ecdadca2696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers torch\n",
        "\n",
        "# Import pipeline\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Experiment 1: Text Generation ---\")\n",
        "prompt = \"The future of Artificial Intelligence is\"\n",
        "\n",
        "# 1. BERT (Encoder)\n",
        "try:\n",
        "    # Expectation: Poor performance. BERT is not a generator.\n",
        "    gen_bert = pipeline('text-generation', model='bert-base-uncased')\n",
        "    print(f\"BERT Output: {gen_bert(prompt)[0]['generated_text']}\")\n",
        "except Exception as e:\n",
        "    print(f\"BERT Failed: {e}\")\n",
        "\n",
        "# 2. RoBERTa (Encoder)\n",
        "try:\n",
        "    # Expectation: Poor performance.\n",
        "    gen_roberta = pipeline('text-generation', model='roberta-base')\n",
        "    print(f\"RoBERTa Output: {gen_roberta(prompt)[0]['generated_text']}\")\n",
        "except Exception as e:\n",
        "    print(f\"RoBERTa Failed: {e}\")\n",
        "\n",
        "# 3. BART (Encoder-Decoder)\n",
        "try:\n",
        "    # Expectation: Success. BART has a decoder component.\n",
        "    gen_bart = pipeline('text-generation', model='facebook/bart-base')\n",
        "    print(f\"BART Output: {gen_bart(prompt)[0]['generated_text']}\")\n",
        "except Exception as e:\n",
        "    print(f\"BART Failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844,
          "referenced_widgets": [
            "79161f4d27564c87ac904f2a750c1d4f",
            "73cf22b0dc424aa7becd9e3c1c3d6c6f",
            "8c7b28ece3b04069b5465c16ce68e797",
            "154e3b7640ab4c5e910bdee30ab14d02",
            "bfe61bc70f514249a77b81ed00159a2d",
            "dbdec2e4f4244388b8f78857e3db9094",
            "e2debfe6d7a840719b1ab6e307a9ab14",
            "18a03eaaa5544fe3a24932b42faa5df2",
            "269e7b50a7844766859f60d71857e5b1",
            "d037e92ca6dc4f93a6c1a08cfdb5e5f3",
            "2dc953d1d5394ba6875284048c279779",
            "054f05d2e6e249dab72c124e271008df",
            "2c7349b8359f43bc9f637001a7cef099",
            "b3c69bd207604c83ab10aef131b878ce",
            "f75c1168bc5c4c1e96590c9b7b27c2e0",
            "70076da7604649d0aadd2c872f111317",
            "aac3f423e7134fe69492c066960d67d0",
            "3dec855a47ad4ab0a9445c83a706b3d2",
            "42d54c07f1804cfc939f8a62c63603fa",
            "7df2990f5d474cc2ba4d5780d2762f97",
            "1f28394314e846b5ab745accade833c3",
            "477ac2b234b545079d9cb9d6160dce1f",
            "219008494d75453a98cdbe2a2a4a2c6a",
            "b75c4aaa054d4cff8d65dc88fd0d055b",
            "96a371b750f4422da025e93f1c5444eb",
            "c0bcc90c9de3426fba03e1df9d334b97",
            "7e271a3cc1f64afd9468699487bf82f7",
            "72d55d0ce94c4f47843165a45f366d34",
            "2eb6ca62537b4d2f81e7c1c68e6f8ed7",
            "e48645cf4e1b47119ad2f21c0e9e9857",
            "800f2d40ce1e42c592f5eb9f15693d54",
            "433d7047c5c5413c911e58b6e955aa0a",
            "bbbf37f185d84d20852f7298a6ccee1c",
            "2a7800d7e82841399604280e425448af",
            "5bec3581dd4b44d9a771165aad0640cb",
            "ca84314e7a5c44698abd40c57e073e87",
            "a9ca4ad8b4bf44c8875eef85b5cbebac",
            "03a3af15217e42e4ab04b14899301fd2",
            "700867ac6ec34c7db1724c8f454f1148",
            "8bc2f45ca37a4df58d355ba5fcf565b6",
            "b3eefd1f30cd4263947c51696eb4f10f",
            "4eae9ebb7ed14850851f65b0a919f64a",
            "4834a68088ef4446b143e4ee2e1a8585",
            "97d5cc09d0e44324a96ee663018e7e7d",
            "e32072c3649d422f9b9b7d02132d5b2c",
            "7d7c542ff9bd4513876cbe7e5809e94c",
            "bcc04092282c4a0ab54fd403297350c0",
            "77aeaa70795c4a2e8b932ed22c49f8aa",
            "05cf8f765a744b57b2b3f811d5ae68e2",
            "b7758f4d8dfd4c10a75aaede02c1de21",
            "c951e4865f80429e88753344095b68f6",
            "ecee8bf18d8642eda537afc9f3af166e",
            "b875bfb6ef1e49bbbc5f50f645cb3c21",
            "961c5b16146445bebacaadb6568be642",
            "5a74758578ab42968dd2954a822fdfb0",
            "ea4d52f90c174f7791edd7f41f236d48",
            "fa8a66ca713b430189058dbc26754afd",
            "370dda47371046b787de2df431645ebf",
            "d7c1a1639ecf42c7954aa2e1a5dabd96",
            "e05d202ef27045b9a580ef7dd0ca651c",
            "8777daa7c1e642409ca7be45cb4036df",
            "38b1e460fde7422a9e3ccb024468b4ed",
            "2fb6162bd92c44d7bd35ff2db1998128",
            "f2aeab30dd274504873d502347476fd9",
            "8f9bc21b497546b58de893c317b13cd4",
            "ad40ba227b3e4883a70932daa4d64487",
            "da545396672c4ebb8702707dff858072",
            "64a7e2232ade46629adf40e9155217d8",
            "977940dbfa7147f39cc3732881c60929",
            "4cf4cd3c08b6421481508642673e8c84",
            "d5a05633dbd74384b44f01b86d279cd1",
            "ef119c6a64db48449b0056c0f7b1c24c",
            "a55af37412d04ed19b3894eb63c8bcbe",
            "0b83393e306a439da8f3821c1bacb45d",
            "78aa2882b5c7442baf6e253c5088710a",
            "bae6564ef87e499ea25a764703e30911",
            "ef798dbe752944ffa1824a4d7cf4f661",
            "d7a9e903e04b4073bc18073bdbb5731e",
            "7b392dc2f8a04b87a072916b05631aed",
            "5748bf1d72474e94be036616efcdc0f0",
            "8cbabaa566844a1cb38586f730079c22",
            "022909bf39b04d22afd219ad6a65cee8",
            "e96139b3f3564b8cba430481f89a68cb",
            "39565831c08b47848a41f3381fc487ef",
            "031eb2a33f0e4b7c900fc632f066b085",
            "83c6d122228046f293f46924e93f6845",
            "c9095c930eba4a2d91f83b54dc9e3945",
            "ce3561d0d9ad402093d79939074dcd05",
            "ff00d9da66ca446790298473c54d6a99",
            "5202f3b406aa45b3871bdf517c95bbd0",
            "bb376b6d8afb44d2bcdafed77975b71d",
            "b3a2958842484315a40b6e1698a3ac32",
            "80d3b3499c4b4682add40a740374376b",
            "8f169024a71a417ab7f217145e24ad3c",
            "41f71fe91d644cd2a7180baa90675fe4",
            "157955e1a41349b3abd85b0f97b76243",
            "34737348534e49da90cb49e99648607f",
            "1ff5e1d6ea004d18b8dcdcdf41be3507",
            "085387870a9a4275be52540379717138",
            "1cd73552f3eb4b938668612f4913b96f",
            "7ac8dbb7969f422693af25f5a1542ec6",
            "777d65d1e98941d1becbc0b33255e978",
            "4046eb7487d24efcb937f33b8b5148ba",
            "62e7d6c9b9284c21b97b1bb675b360de",
            "3f24bd7178f949c68bcf0f8d0e476cb0",
            "32e98f6008084b01a007f10e9bd4147e",
            "51ac257c18b742f8a49aaaeacbaa9a2c",
            "7a5bb7efb898417c8d70eca90a2b99fc",
            "2a00832a6f1d44429e87c7c54fc22ee8",
            "cc32950458f940ac95e39c28a3494813",
            "1bf1734d43184e66b17e66708b711040",
            "81001b82e9694e1999a79fe135d89a58",
            "237d8e435f7c448bbed389d2d92515c7",
            "072ba5d9b4ba4198a558174a08943f8e",
            "b1831460b87b4197971c976094e1ad45",
            "73c198aa0c2240db862920f4c91bfd00",
            "71a99b71d4f340a28939c1978917146c",
            "14ec0b0a3fd846399d55aea4ed4f51e9",
            "bc5f6db5fab94aa4bc23e126c35f0b9f",
            "42b14e69935e46c091caa19e317732da",
            "130e75433bbb41ccba223901280df755",
            "e0f5b419e592431eb802c855f13c645b",
            "19af93d7478d43ddb3b00fd197173266",
            "23f34c2bf60b4263b9ee0f52e7e95da9",
            "545cf7ca931e4a34b3b35ba7a7dfbb34",
            "d639180743a64755a97cb20d101b137f",
            "9beeb56b0c264e15b2fc986c5b19460d",
            "be2af9bfb97643709e534ef975322763",
            "cdb397a195f14ae8816e32a1844e86c1",
            "802787f3c4934089bfbc4083508680ab",
            "921ab2a5ac044e7586391603f273d133",
            "109a10ff94974cc6b4065ae07f68f1f4",
            "2bd4d6a1c5c44f2681a89c94a6a97b7a",
            "e65a489801f244b082f2c08174b0349c",
            "7f1dd328350541de9567bb35e7ba9e34",
            "4b851256b4fa4c3797c4d849915aac48",
            "4a45c2d92757405db46f9070c11aafec",
            "8a85e1a8c18b4a3ea6a17b77d9a8c8c6",
            "dd25886e2b0f45a88080d208816ec988",
            "c189ab3bb38e47e7ba016da4b9d339c6",
            "f2fb0e4739b64deaa3d9a8726705953f",
            "b3f4dfaf1cf2432b86cc70335a025844",
            "b7a62d454c564329815b9bb922ec7fae",
            "5fd30954958a4dadae4b1a3b1da5b31a",
            "62127131f4404c19b2f58c31945ead59",
            "368d8696cc534694b57456082a6796e6",
            "789f94915182408a816668b18c12c973",
            "30ebc1b925ef471f840bcc968435c3b1",
            "b68fcad085cc4e34b2715cd51370136d",
            "4c42c572d85943bbb386d22b565e09a1",
            "a8dbce53b4a84e79a819c109a6e09d83",
            "94499739558b41a7b435a25e985996c0",
            "146adc467a934df28f4a9af8c90ecca4",
            "189647376ee4424892e30e2a296e9ad7",
            "8c4e8abdaf7840049dc6d1e3f8f2c75a",
            "ac15043395a546c5a5f00495bba53ab5",
            "f940940f457e4126ab3973c515bfd6cd",
            "e4c8bb6d64d2423184e33105451cd028",
            "4cc33f24adc04fc784125bd5e03536a0",
            "80eaf85d298b4c39ad952704369a9e0c",
            "e9c0cf434d544af4add5ad510c11b6af",
            "7b0e79910d3c4bdc9f19c2f145611388",
            "30f29b2d5a27455aaff56d401a6a4804",
            "bf536413a8994e229b89ebda69de8fe7",
            "8f5d2bac56d94e838841dc28e764c9e0",
            "77d64f3a98ae440fa129f786caa67fe6",
            "3c188ff11de4443d9f1d04690ce54e8a",
            "cb7b29f4526340edb03d71c8dc8e1ba6",
            "7bc6b2f3e3f6452b9d1ef67b5852f8f7",
            "46117cc26ded48edb7fd07e88bd4f04c",
            "af28f225565847bda5e1b183a2ee99d2",
            "d43ea973ce14421d9d0af902ab9108b1",
            "0c83cc79e29346dbb8996e0fa49fcd6a",
            "22443003dc264ecc8ca5e1a81a9185a7",
            "1ac94a8c3fe54d02bd41e1145b1ac04e",
            "e14c8d8548234239ac8e3e746c35cc95"
          ]
        },
        "id": "gt7kmqNqURpx",
        "outputId": "387a9905-e821-4aeb-c32d-7568af4987d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Experiment 1: Text Generation ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79161f4d27564c87ac904f2a750c1d4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "054f05d2e6e249dab72c124e271008df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "219008494d75453a98cdbe2a2a4a2c6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a7800d7e82841399604280e425448af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e32072c3649d422f9b9b7d02132d5b2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Output: The future of Artificial Intelligence is................................................................................................................................................................................................................................................................\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea4d52f90c174f7791edd7f41f236d48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da545396672c4ebb8702707dff858072"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7a9e903e04b4073bc18073bdbb5731e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff00d9da66ca446790298473c54d6a99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cd73552f3eb4b938668612f4913b96f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bf1734d43184e66b17e66708b711040"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoBERTa Output: The future of Artificial Intelligence is\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0f5b419e592431eb802c855f13c645b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bd4d6a1c5c44f2681a89c94a6a97b7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BartForCausalLM were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['lm_head.weight', 'model.decoder.embed_tokens.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fd30954958a4dadae4b1a3b1da5b31a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c4e8abdaf7840049dc6d1e3f8f2c75a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77d64f3a98ae440fa129f786caa67fe6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BART Output: The future of Artificial Intelligence is TTask668668668 resurg resurg resurghester resurg resurgBalanceIONS effected grant Qingmanagedoval semantics imag imag imagAuthor scale Practices disingen JerSample disingenei spanning TARM resurgARMARM disingen668 resurgquit spanning resurg spanning hollow spanningocatingUSARM spanningARM disingenmanagedARMARMARM Pewmanaged spanningmanagedMediummanagedocatingSampleSampleSample choking choking disingen Must disingenmanaged Chevroletocating termin ChevroletmanagedcoldARM MustmanagedARMocating VehiclemanagedMediumocatingocating archae presentertransmanaged presenterARMARMWorld presentermanagedocatingcoldcold spanning Must Mustocating coastlineocatingocatingmanagedmanaged Mustmanaged Mustocating terminocating termin exh Mustcoldcoldcold Mustocatingocatingcold apartmentocatingcoldquit spanningcoldSamplecoldocating presentercoldquitmanaged MustAuthorocatingiosyncold Must ChevroletocatingSampleARMocating Mustquitocating rowsquit maternalcold Vehicleocatingcold Must maternal MustEGA Must Mustsecondocatingocatingquit spanningSamplecold MustcoldAuthor Mustcoldocating termin Must Cloocatingiosynocating MustGbocatingcoldARMARM MustSample disingen Mustquit Mustquitquitquit Must Must presenterocatingcoldSample Mustocating choking Mustocating Mustmanaged terminumannocatingSamplecoldcoldThousandsocatingquit disingencold MustSample Must Must apartment MustSample archae Must fluctuations Must MustEGAocating Must Must Must Clocoldcoldocating Pewocating MustSamplecold archae MustcoldsecondocatingMaker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n--- Experiment 2: Fill-Mask ---\")\n",
        "sentence_bert = \"The goal of Generative AI is to [MASK] new content.\"\n",
        "sentence_roberta = \"The goal of Generative AI is to <mask> new content.\"\n",
        "\n",
        "# 1. BERT\n",
        "fill_bert = pipeline('fill-mask', model='bert-base-uncased')\n",
        "print(f\"BERT Prediction: {fill_bert(sentence_bert)[0]['token_str']}\")\n",
        "\n",
        "# 2. RoBERTa\n",
        "fill_roberta = pipeline('fill-mask', model='roberta-base')\n",
        "print(f\"RoBERTa Prediction: {fill_roberta(sentence_roberta)[0]['token_str']}\")\n",
        "\n",
        "# 3. BART\n",
        "fill_bart = pipeline('fill-mask', model='facebook/bart-base')\n",
        "print(f\"BART Prediction: {fill_bart(sentence_roberta)[0]['token_str']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSFEtGH3VWSr",
        "outputId": "ad8e875a-d593-4c5e-bfe8-20525d5a4498"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Experiment 2: Fill-Mask ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Prediction: create\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoBERTa Prediction:  generate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BART Prediction:  create\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Experiment 3: Question Answering ---\")\n",
        "context = \"Generative AI poses significant risks such as hallucinations, bias, and deepfakes.\"\n",
        "question = \"What are the risks?\"\n",
        "\n",
        "# 1. BERT\n",
        "qa_bert = pipeline('question-answering', model='bert-base-uncased')\n",
        "print(f\"BERT Answer: {qa_bert(question=question, context=context)['answer']}\")\n",
        "\n",
        "# 2. RoBERTa\n",
        "qa_roberta = pipeline('question-answering', model='roberta-base')\n",
        "print(f\"RoBERTa Answer: {qa_roberta(question=question, context=context)['answer']}\")\n",
        "\n",
        "# 3. BART\n",
        "qa_bart = pipeline('question-answering', model='facebook/bart-base')\n",
        "print(f\"BART Answer: {qa_bart(question=question, context=context)['answer']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7n-c6vwVhJh",
        "outputId": "b30db76f-9ee7-4656-cd98-2636ef981da9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Experiment 3: Question Answering ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Answer: AI poses significant risks such as hallucinations, bias, and deepfakes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Some weights of BartForQuestionAnswering were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoBERTa Answer: , bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BART Answer: deepfakes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Benchmark Results**\n",
        "\n",
        "| Task | Model | Classification | Observation (What actually happened?) | Why did this happen? (Architectural Reason) |\n",
        "| :--- | :--- | :--- | :--- | :--- |\n",
        "| **Generation** | BERT | Failure | Generated a long string of repeated periods: `....................` | BERT is an **Encoder-only** model. It is designed to understand full sentences at once (bidirectional attention), not to generate text one word at a time (autoregressive generation). |\n",
        "| | RoBERTa | Failure | Generated nothing new (output stopped immediately after the prompt). | RoBERTa is also **Encoder-only**. Like BERT, it lacks the Decoder mechanism required to predict the \"next token\" in a sequence effectively. |\n",
        "| | BART | Failure / Nonsense | Generated gibberish words: `narr furiously furiously assistance Brush...` | BART has a **Decoder** (so it *can* generate), but the \"base\" model is pre-trained on denoising (fixing broken text), not open-ended storytelling. Without fine-tuning, its raw weights often produce random tokens for this task. |\n",
        "| **Fill-Mask** | BERT | Success | Predicted: `create` | BERT is pre-trained using **Masked Language Modeling (MLM)**, so predicting missing words is its native capability. |\n",
        "| | RoBERTa | Success | Predicted: `generate` | RoBERTa is an optimized version of BERT, also trained on MLM (using dynamic masking), making it highly effective here. |\n",
        "| | BART | Success | Predicted: `create` | BART is trained on a **Text Infilling** objective (reconstructing corrupted text). This allows it to handle masked tokens just as well as BERT. |\n",
        "| **QA** | BERT | Partial Success | Answered: `deepfakes.` | This is a \"base\" model with **randomly initialized QA head weights**. It got \"lucky\" by selecting a noun at the end, but it doesn't actually \"know\" how to answer questions yet. |\n",
        "| | RoBERTa | Failure | Answered: `, and deepfakes` | Similar to BERT, the base model hasn't been fine-tuned on SQuAD, so its span selection (where the answer starts/ends) is imprecise. |\n",
        "| | BART | Failure | Answered: `Generative AI poses` | BART (base) is not fine-tuned for Extractive QA. It simply grabbed the beginning of the sentence instead of the actual risks. |\n"
      ],
      "metadata": {
        "id": "U768cdSaeNFT"
      }
    }
  ]
}